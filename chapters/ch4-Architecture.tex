\ifx\wholebook\relax\else

% --------------------------------------------
% Lulu:

    \documentclass[a4paper,12pt,twoside]{../includes/ThesisStyle}

	\input{../includes/macros}
	\input{../includes/formatAndDefs}

	\graphicspath{{.}{../figures/}}
	\begin{document}
\fi

\chapter{Sista Architecture}
\label{chap:architecture}
\minitoc

The overall thesis focuses on the design and implementation of an optimising JIT compiler for Pharo, written in Pharo itself, running in the same runtime than the optimised application on top of the existing runtime environment. In this chapter, we detail the architecture designed and implemented to make it work.

Cogit was extended to detect hot spot through profiling counters in non optimised n-functions. When a hot spot is detected, Cogit immediately calls Scorch in Pharo. Scorch then looks for the best v-function to optimise based on the current stack, optimises it and installs the optimised version. To perform optimisation, Scorch may ask Cogit to introspect specific n-functions to extract type information and basic block usage from previous runs. Once installed, the VM can execute the optimised v-function at the next call to the function. As the VM runtime is hybrid between an interpreter and Cogit, the optimised v-function may be interpreted or compiled to an optimised n-function by Cogit. As optimised v-functions have accessed to operations not normally possible by v-functions, both the interpreter and Cogit were extended to support the new operations.

Due to speculative optimisations, optimised v-functions may contain guards to ensure optimisation-time speculations are valid at runtime or dynamically deoptimise the code. If a guard fails, the optimised code needs to be deoptimised and the stack editing to resume execution with non optimised code. Cogit is only able to map a stack frame from n-function state (values in register, machine-specific calling convetions, etc.) to a single stack frame in v-function state as if the function was interpreted (all values are on stack). Hence, when an optimised n-function needs to be deoptimised, Cogit maps the stack frame to v-function state, provides it to Scorch, which maps the stack frame holding the optimised v-function to multiple stack frames with non-optimised v-functions. The execution can then resume using non optimised code.

\section {Function's optimisation}

%overview

%first, repeat all steps.

%second, explain problem with responsiveness and past from next chapter the explanation with critical and background mode.

%Detail

%Hot spot detection ?

%VM call-back ? => explain what's in C and what is not in C

%Stack search, explain almost never bottom stack frame ?

%optimisation. Maybe a short paragraph

%Either postpone or installion (include dependencies)

%restart code, return, frame just after application frame


\begin{enumerate}
	\item \emph{Hot spot detection:} When the baseline JIT compiler generates a non optimised n-function, it inserts profiling counters. Each time the execution flow reaches a counter, it is incremented and when the counter reaches a threshold, the function is detected as a hot spot.
	\item \emph{VM call-back:} When a hot spot is detected, a specific Slang routine is called. The routine makes sure the stack frame with the tripping counter is reified or reify it, then it performs a virtual call with a selector specified in Smalltalk with the reified stack frame as receiver. This moves hot spot detection management from the VM to Smalltalk.
	\item \emph{Stack search:} In Smalltalk Scorch introspects the reified stack and looks for a function to optimise. Based on multiple heuristics, one of the bottom stack frames' functions is selected for optimisations (It selects a function where as many closures as possible can be inlined).
	\item \emph{Optimisation:} Scorch has then a limited amount of time to optimise the selected v-function. To speculate on types, Scorch request the VM to introspect specific n-function to extract the type information found in inline caches and profiling counter to determine basic block usage. The optimisations performed are standard and basic (mainly speculative inlining, array bounds check elimination, global value numbering, loop invariant code motion). Scorch finally generates an optimised v-function encoded in an extended bytecode set annotated with deoptimisation and dependency metadata.
	\item \emph{Installation:} The optimized function is installed, either in the method dictionary of a class if this is a method, or in a method if it's a closure. The dependencies are installed in the dependency manager so that if new code is loaded, code that may be dependent is discarded.
	\item \emph{Code restart:} The execution flow then returns to the tripping function to resume the execution of the code. The return is performed as a normal return, no special VM routine is called. If an optimised function is installed, it will be activated at next call.
\end{enumerate}




\section {Function's deoptimisation}

The dynamic deoptimization process, again, is very similar to other virtual machines \cite{Fin03a, Holz92a}. The main difference is that it is split in two parts: firstly the baseline JIT maps  machine state to a state as if the bytecode interpreter would execute the function, second the deoptimizer maps the interpreter state to the deoptimized interpreter frames.

During dynamic deoptimization, we deal only with the recovery of the stack from its optimized state using optimized functions to the  unoptimized state using unoptimized functions. The unoptimized code itself is always present, as the bytecode version of the  unoptimized function is quite compact. As far as we know, modern VM such as V8~\cite{V8} always keep the machine code representation of unoptimized functions, which is less compact than the bytecode version, so we believe keeping the unoptimized bytecode function is not a problem in term of memory footprint.

\begin{enumerate}
\item \emph{Deoptimization trigger:} Deoptimization can happen in two main cases. First, a guard inserted during the optimization phases of the compiler has failed. Second, the language requests the stack to be deoptimized, typically for debugging.
\item \emph{JIT map:} The first step, done by the baseline JIT compiler is to map the machine code state of the stack frame to the bytecode interpreter state, as it would do for an unoptimized method. This mapping is a one-to-one mapping: a machine code stack frame maps to a single interpreter stack frame. In this step, the baseline JIT maps the machine code program counter to the bytecode program counter, boxes unboxed values present and spills values in registers on stack.
\item \emph{Deoptimizer map:} The JIT then requests the deoptimizer to map the stack frame of the optimized bytecoded function to multiple stack frames of unoptimized functions. In this step, it can also rematerialize objects from values on stack and constants, whose allocations have been removed by the optimizer. The stack with all the unoptimized functions at the correct bytecode interpreter state is recovered.
\item \emph{Stack edition:}
The deoptimizer edits the bottom of the stack to use the deoptimized stack frames instead of the optimized ones, and resumes execution in the unoptimized stack.
\end{enumerate}

+ Debugger and code loading support: reuse discarding logic and deopt logic

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Required language evolutions}

evolutions required for support

\subsection{Profiling counters}


To detect frequently used method, counters were introduced in code compiled by the baseline JIT, triggering a call-back when the counter reaches a specific threshold. Profiling counters add some overhead. As the baseline JIT is used both to compile non optimised and optimised code, compilation became conditional to introduce counters only in non optimised code. For this purpose, each bytecoded function is marked as being optimized or not thanks to a bit in the header. If the function has not yet been optimized, the baseline JIT generates counters in the machine code that are incremented each time they are reached by the flow of execution. Once a counter reaches a threshold, a call-back requests the runtime optimizer to generate optimized code.

Based on \cite{Arn02}, we added counters by extending the way the baseline JIT generates conditional jumps to add counters just before and just after the branch. In several other VMs, the counters are added at the beginning of each function. The technique we used allowed us to reduce the counter overhead as branches are 6 times less frequent that virtual calls in the Smalltalk code we observe on production application. In addition, the counters provide information about basic block usage. Every finite loop requires a branch to stop the loop iteration and most recursive code requires a branch to stop the recursion, so the main cases for which we wanted to detect hot spots for are covered.

TODO why pinned array and not normal object like symbol literals ? => because direct access to object slot 
Using an immovable object results in 
- not having to add new method map entries
- not having to add new map/reference scanning machinery to update derived pointers (pointers into objects)
- the most direct access to the counter and hence the simplest possible instruction sequence (remember the AbstractInstrcution set is somewhat RISC like)
ENd TODO

To make the processor instruction-cache happy, counter values could not be next the machine code of each function. Indeed, doing so reuire the processor to flush the instruction-cache each time the counter is modified, slowing down massively code execution. To keep it efficient, at machine code compilation time a function is associated with a pinned array holding the counter values. The pinned property of the array allows the machine code to refer directly to the counter addresses, without having to do any garbage collection extension.


\subsection{Extended bytecode set}

To support unsafe operations, the bytecode set needed to be extended. B\'era and Miranda describes the extended bytecode set used \cite{Bera14a}. The extended bytecode set design relies on the assumption that only a small number of new bytecode instructions are needed for the baseline JIT to produce efficient machine code. Three main kind of instructions were added into the bytecode set:
\begin{itemize}
\item \textbf{Guards}: guards are used to ensure a specific object has a given type, else they trigger dynamic deoptimization.
\item \textbf{Object unchecked accesses}: normally variable-sized objects such as arrays or byte arrays require type and bounds checks to allow a program to access their fields. Unchecked access directly reads the field of an object without any checks.
\item \textbf{Unchecked arithmetics}: Arithmetic operations needs to check for the operand types to know what arithmetic operation to call (on integers, double, etc.). Unchecked operations are typed and do not need these check. In addition, unchecked operations do not do an overflow check and are converted efficiently to machine code conditional branches if followed by a conditional jump.
\end{itemize}

We are considering adding other unchecked operations in the future. For example, we believe instructions related to object creation or stores without the garbage collector write barrier could make sense.

As the optimized methods are represented as bytecodes, one could consider executing them using the bytecode interpreter. This is indeed possible and we explain later in section \ref{interpreter} that in very uncommon cases it can happen in our runtime. However, improving the performance to speed-up the bytecode interpreter or to speed-up the machine code generated using the baseline JIT as a back-end are two different tasks that may conflict with one another. We designed the bytecode set so the machine code generated by the baseline JIT as a back-end is as efficient as possible, not really considering the speed of the interpretation of those methods as they are almost never interpreted in our runtime.


\subsection{Call-backs}

As in our implementation the runtime optimizer and deoptimizer are implemented in Smalltalk and not in the virtual machine itself, we needed to introduce callbacks activated by the virtual machine to activate the optimizer and the deoptimizer. 

These callbacks use the reification of stack frames available for the debugger to inform the language which frame had its method detected as a hot spot and which frame has to be deoptimized.


\subsection{Machine code introspection}

%merge 2 part, ยง1 and pargraph 2-3
To extract information from the machine code version of a method, we added a new primitive operation \emph{sendAndBranchData}. This operation can be performed only on compiled methods. If the method has currently a machine code version, the primitive answers the types met at each inline cache and the values of the counters at each branch. This information can be then used by the runtime optimizer to type variables and to detect the usage of each basic block. The primitive answers the runtime information relative to the compiled method and all the closures defined in the compiled method.


A primitive operation was added in the language to extract the \emph{send and branch data} of the associated machine code of each function. It works as follows:
\begin{itemize}
\item If the function is present in the machine code zone, then it answers the \emph{send data}, which means the types met at each virtual call site based on the state of the inline caches, and the \emph{branch data}, which means the number of times each branch was taken at each branch.
\item If the function is not present in the machine code zone, then this primitive fails.
\end{itemize}

The data is answered as an array of array, with each entry being composed of:
\begin{itemize}
\item the bytecode program counter of the instruction.
\item either the types met and the function founds for virtual calls or the number of time each branch was taken for branches.
\end{itemize}

\subsection{Runtime optimiser and deoptimiser}

Explain simple behavior.

Maybe it makes sense to say Context are the same as objects.

deoptimizer 
Doc: my blog post + sista arch

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Optional language evolutions}

evolutions not required, but would be nice to get performance.

\subsection{New memory manager}

%I NEED TO CITE THE SPUR PAPER HERE.

The first problem met was related to the complexity of the existing memory manager (called V3) in the virtual machine. The memory manager is responsible for the representation of object in memory, as well as object allocation and garbage collection. The main issue lied with memory representation of objects: V3 was designed for an interpreter-based VM running heaps of several Mbs at most and it did not allow the JIT to generate efficient machine code nor scaling to large heap of objects.

\paragraph{Efficient JIT compilation.} Let's take a simple example. With V3, an object can access to its class in three different ways. Firstly, immediate objects\footnote{An immediate object is an object directly encoded in the object pointer, typically tagged integers.} access their classes through a special table, a list of 16 common classes have their instances access their class through another special table, while the rest of the objects have a pointer to their class in their header. In machine code, efficient class access becomes critical for efficient type tests (typically deoptimisation guards) and for inline caches, used in the baseline JIT to collect virtual calls receiver types. With V3, each class access in machine code requires to compile the three different paths. 

\paragraph{Heap scaling.} The second main issue was related to heap scaling. Let's take another simple example. V3 memory manager requests 1 Gb of memory to the operating system at start-up to keep all the heap contiguous, instead of segmenting its heap in smaller portions. This is very problematic in multiple OS such as Windows, where the OS may refuse to provide such a large amount of memory. 

(CITE Spur paper)
\cite{Mir15a}

Spur solutions.

pinned objects

Doc: spur paper

\subsection{New bytecode set}
New bytecode set needs to be discussed (not only extensions).

\subsection{Register allocation}

Linear scan and reg alloc, plus branches
Doc: TODO

\subsection{Read-only objects}

%I NEED TO CITE THE WRITEBARRIER PAPER HERE.

\cite{Bera16b}

One of the main problem encountered while trying to improve the performance of the Pharo runtime was literal mutability. In most programming languages, if the program executes a simple double addition between two double constants the compiler can compute at compile-time the result. In Pharo, as literals are mutable, one of the double constant may be accessed through reflective APIs and mutated into another boxed double, invalidating the compile-time result. 

To solve the problem, I introduced a feature, called read-only objects. With this feature, a program can mark any object as read-only. Such read-only objects cannot be mutated unless the program explicitly revert them to a writable state. This feature was introduced with little to no overhead on the production VM (CITE). 

Literals can now all be read-only objects, and any attempt to mutate a read-only literal is caught and, if the literal was used for compile-time computation, dependant optimised code is discarded if the mutation happens. This way, traditional compiler optimisation can be applied to the Pharo runtime.

\subsection{Closure implementation}


The second major issue encountered was related to the closure implementation. 

FullBlock
Doc: ? well... the FullBlock talk

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}


\ifx\wholebook\relax\else
    \end{document}
\fi