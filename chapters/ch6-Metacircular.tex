\ifx\wholebook\relax\else

% --------------------------------------------
% Lulu:

    \documentclass[a4paper,12pt,twoside]{../includes/ThesisStyle}

	\input{../includes/macros}
	\input{../includes/formatAndDefs}

	\graphicspath{{.}{../figures/}}
	\begin{document}
\fi

\chapter{Metacircular optimising JIT}
\label{chap:metacircular}
\minitoc

%Intro
By design, Scorch's optimiser and deoptimiser are written in Smalltalk and are running in the same runtime than the optimised application. This design leads to multiple problems similar to the ones existing in metacircular virtual machine. 

%single-threaded -> for comparison with Graal and co later
As Pharo is currently single-threaded, it is not possible to run Scorch in a concurrent native thread. To optimise code, Scorch requires either to interrupt the application green thread temporarily or to postpone the optimisation to a background-priority green thread. The deoptimiser cannot however postpone its task as it would block completely the running application, hence it has to interrupt the application green thread until the deoptimisation is done.

%introduction of the main issue
We call the \emph{infinite recursion} problem the main issue encountered both with the optimiser and the deoptimiser. When a hot spot is detected in the optimiser code, it interrupts itself and starts to optimise one of its own function. While doing so, the same hot spot may be detected again, leading the optimiser to interrupt itself repeatedly. When the deoptimiser requires to deoptimise one of its own function to be able to keep deoptimising an optimised frame, it calls itself, which may require to deoptimise the same function, leading the deoptimiser to call itself again and again.

%Different constraint so different solutions
The optimiser and deoptimiser have different constraints. For example, it is possible to disable temporarily the optimiser, which in the worst case leads to some functions not to be optimised, but it is not possible to disable temporarily the deoptimiser as it is required to execute code. As they have different constraints, they need different solutions for the infinite recursion problem.

%Outline and solution
This chapter explains the design used to avoid the infinite recursion issue in both the deoptimiser and the deoptimiser. The problem is solved in the optimiser by defining a critical portion of code where the optimiser is disabled temporarily. The deoptimiser solves the problem by using code completely independent from the rest of the system that cannot be optimised, hence never requires to be deoptimised. The last section discuss similar design issues in other VMs and when relevant, compares our solution to other solutions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Scorch optimiser}

%Intro, what Scorch optimiser does and critical mode.
Scorch optimiser is activated by the VM when a hot spot is detected. It determines, based on the current stack, a v-function to optimise. As Pharo is single-threaded, this is done by interrupting the application green thread. Once the v-function to optimise is determine, Scorch gets started in critical mode: it attempts to generate an optimised v-function in a limited amount of time. If it succeeds, the optimised v-function is installed and used by further calls on the function. If Scorch fails to generate the optimised v-function in the limited amount of time, if queues the v-function in a background compilation queue. In any case, the application is then resumed.

%background mode
When the application becomes idle, if the background compilation queue is not empty, Scorch gets activated in background mode. It produces and installs optimised v-functions for each function in the compilation queue without any time limit. 

\subsection{Infinite recursion issue}

%repeat problem for optimiser
As Scorch is written in Smalltalk, it can theoretically optimise its own code. In practice, if it happens, it may lead to an infinite recursion. Indeed, each time Scorch tries to optimise anything, before reaching the point where it can install the optimised function, it may interrupt itself (as it would interrupt any running application) to start optimising one of its own function. If a frequent portion of code is detected at each optimisation attempt, then Scorch never reaches the point where it can install optimised function because it keeps restarting new optimisation on its own code.

%slow down - critical
In critical mode, Scorch has a limited time window. Hence, if the infinite recursion issue happens, the optimiser gets stuck until the time window ends, then the application resumes without any optimised function installed. Hence the application gets slower.

%slow down - background
In background mode, the optimiser is slower because the optimiser gets activated in critical mode multiple times when detecting hot spot in the optimiser itself, and in critical mode it gets stuck for the time window. After a while, the code still get optimised and installed. 

The problem is therefore that the application executed gets really slow because of time wasted stuck in critical mode until it reaches peak performance. In addition, peak performance takes a long time to reach because the optimiser successfully installs code only in background mode or if it does not get stuck in critical mode until its own code is optimised. 

\subsection{Current solution}

The first solution we thought of is to disable to optimiser when it is running. We believed it would solve the problem at the cost that the optimiser would not be able to optimise itself, and we were willing to to accept this consequence.

%Optimiser can be disabled
The optimiser is considered disabled when each call-back normally starting the optimisation of code is modified not to do anything at all. In this case, the application keeps running, but no further code is optimised until the optimiser gets enabled again.

%call-back removal / addition implementation
To implement our first solution, we changed the VM call-back activating the optimiser to uninstall itself upon activation. Then, we changed the optimiser so that when it resumes the application, after postponing the optimisation or installing optimised code, it installs back the call-back. This way, we thought the optimiser would never end up in a situation where it optimises itself, solving entirely the problem.

%using opt libs
This solution has a significant advantage: it is quite simple both conceptually and implementation-wise, while it completely avoids the infinite recursion problem. It has however a major drawback: Scorch cannot optimise its own code any more. Of course, Scorch uses core libraries that can be optimised. The main case are the core collections, if the application optimised is also using core collections, they may get optimised, then Scorch ends up using an optimised collection library. For this reason, it is possible that while optimising code Scorch triggers the deoptimiser, and it works perfectly fine.

%can optimise itself through back process
Then, we ran our benchmarks and saw that the problem was solved but the optimiser could still optimise its own code. Our implementation effectively disabled the optimiser, but only while it was on critical mode. Hence, when frequent portions of code of the application were detected, they were optimised or postponed without any issue as the optimiser disabled itself during this phasis, and the application resumed just fine. However, when the optimiser was run in background mode, it was not disabled. Hence, in this case, the optimiser in background was sometimes interrupted by itself in critical mode to get optimised.

%1st sol work and good enough 
This first solution is implemented and works fine. The application runs with significant speed-up over the normal VM. In general, in the production VM, simplicity is really important to keep the code relatively easily maintanable and for each added complexity in the VM we wonder if the complexity is worth the benefit. This first solution is nice because it is simpler than the alternative ones, discussed in the next section, so the optimising JIT may move to production with this design.

\subsection{Discussion and advanced solutions}

%but cannot optimise itself in critical mode
There is still one design issue remaining: the optimiser cannot optimise itself in critical mode. Even worse, as the profiling counters are encoded in 16 bits, if one of them exceeds 65535 on one of the optimiser method while it is disabled, the counters are reset but the hot spot is not detected at all.

%the postpone pb while in critical mode
Based on advises from other people, we considered, instead of disabling the optimiser when it is running in critical mode, to postpone the optimisation to the background mode. In our design, it is quite difficult to do so. Indeed, when the VM call-back starts the optimiser, it provides only a reification of the current stack, the optimiser then needs to scan the stack to select what function it should optimise. 

%Saving current stack impossible
As the current stack is modified upon execution, it is not possible to save it efficiently so that the optimiser can look at it in the background green thread. It is possible, once the optimiser has found what function to optimise, to add it to the background compilation queue. However, as discussed in section \ref{ss:stackSearch}, the optimiser is required to search the stack to find the best function to optimise which is not likely to be the function where the hot spot if detected. 

We therefore believe that instead of disabling the entire optimiser while it is running in critical mode, we could instead disable it only during the stack searching phase in critical mode, which represent less than 1\% of the optimiser's execution time, and postpone the optimisation of the selected function to the background green thread. Hence, only hot spots detected during the stack search phasis would be ignored, while the rest of the optimiser would be optimised at the next idle pause.

As the Sista architecture allows to persist optimised code, the optimiser's code could be preheated through warm-up runs, for example by giving it a list of well-chosen functions to optimise. This way, all hot spots inside the optimiser would be detected ahead of time and optimised before shipping the runtime to production. 

Alternatively, the optimiser's code could be optimised statically by calling itself on its own code, using types inferred from a static type inferencer instead of types providing by the runtime application. This last alternative comes with all the advantages and problems of static ahead-of-time compilation.

%\subsection{Dependencies and optimisations} 

% from 1 old part
%Rephrase -  solution does not forbig Scorch to use optimise libs

% maybe only one sentence ? -> be careful about dependencies
%The first constraint to note when programming Scorch, which may be obvious to the Kernel programmer, is that Scorch cannot depends on any framework or library but the Kernel and Core libraries. Each framework or library in the system relies on the execution engine to perform its code. Scorch is part of the execution engine. Hence, if Scorch relies on an external library and that someone modifies the library, the execution engine may not be stable any more and the runtime completely crashes. In fact, all the Kernel code and Core librairies have similar constraints, they cannot rely on anything to keep the system modular. 

%While writting Scorch, we needed a tool to compress the deoptimisation metadata generated aside from the optimised code. We wanted to use the standard Pharo serializer, Fuel (CITE), but we were not able to do it or further modification on Fuel would break the execution engine.

%In the end, we limited the dependencies of Scorch to the Pharo Kernel and the core collections (exactly: Set, OrderedCollection, Array, ByteArray and Dictionary in addition to the kernel). Any change on one of this dependency may require to change something in Scorch to keep the system running.


%\subsection{Debugging and runtime modification}

%Should I talk about that at all ? I was thinking over a restricted compiling to C but maybe we don't care.

%Maybe rewrite so that formally does not work but in practice it does.

%As any Smalltalk program, it is possible to modify the optimiser while it is running, for example in the debugger. If the modifications leads to incorrect optimiser behavior, then the runtime may crash. To avoid crashes, it may be wise to disable the optimiser while editing it. In practice, this feature is used only by the optimiser implementors. It is very useful to debug the optimiser to understand specific bugs or compiler decisions. With careful understanding of the infrastructure, it is possible in practice to debug the optimiser while it is running and modify its code. The optimiser is set by default to catch all exceptions, failing the optimisation of a specific v-function if an exception was raised. Hence, if the code modification triggers a compile-time exception, the system shall not crash. Unfortunately, in some cases, the optimiser may have silent errors, generating incorrect code without raising exceptions and completely crashing the system.

%The only part of Scorch that cannot really be edited is the deoptimisation metadata generation. Indeed, deoptimisation metadata is also used by the deoptimiser which, as detailled in the following section, has stronger constraints on its code. If one modifies the deoptimisation metadata generated, the deoptimiser may not be able to deoptimise correctly optimised code any more, leading to crashes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%KEEP WRITING FROM HERE

\section{Scorch deoptimiser}

The trap instruction is present in the extended bytecode set and when reached through execution flow, Cogit triggers a call-back to the deoptimiser. In addition, multiple tools in the language, such as the debugging tools, have been changed to call the deoptimiser when the programmer attempts to introspect the stack.

On the contrary to the optimiser, deoptimisation cannot be postponed to a background green thread, or the application green thread may be blocked until the application reaches idle state. In addition, deoptimisation cannot fail or the runtime crashes. If the optimiser failed to create an optimised function, then the execution could simply fall back to non optimised code. If the deoptimiser fails to recreate a non optimised version of the stack, then the system crashes or the application green thread has to be terminated.

%TODO I think I mean it cannot be disabled.

As the deoptimiser cannot fail, it is not possible to solve the infinite recursion problem in the same way than the optimiser. If the deoptimiser request deoptimisation, as for the optimiser requesting optimisation, the programs ends up in an infinite recursion where it keeps deoptimising / optimising itself. In the case of the optimiser, we could simply disable it while it is running, and the entire problem was solved. In the case of the deoptimiser, if we disable it and the deoptimiser request deoptimisation, the program cannot resume using non optimised code and crashes. 

To solve this infinite recursion problem, we implemented two solutions. The first solution attempts to restore the system in a recovery mode when recursive deoptimisation happens. It was used for the first benchmark, but it did not work correctly with benchmarks creating multiple green threads, and making it thread-safe had too many constraints. Then a second solution, used now, was designed and consists in keeping all the deoptimiser code in a library completely independent from the rest of the system that cannot be optimised.

\subsection{Recovery mode}

In this first solution to the infinite recursion problem for deoptimisation, we attempted to keep a recovery state of the whole system. More precisely, Scorch kept a copy of the method dictionaries

 Attempt to recovery state with limited portion that cannot be optimised, issues with green threads and complexity, made it independent.

cannot optimie until flag set / reset.

- recovery state (not working with threads)

too difficult to make thread safe because then up until the flag is set we could not optimise hence can't optimise code in process scheduler.

\subsection{Independent library}

- completely independent and forbid deopt / opt

We could opt it statically.

Strong constraints: no dependency at all (duplicate array and dict), debugging is hardly possible.

Example of debugging -> can't log from deoptimiser. 

\subsection{Debugging and runtime modification}

Modifying the deoptimiser while it is running is also more complex than the optimiser. Optimised code is present in the runtime, and any modification of the deoptimiser is

- any change imply existing code cannot be deopt and hard crashes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related work}

 C++ no problem

\subsection{Graal}

Stack search and deoptimisation in the VM

\subsection{DSL compiled to machine code}

Modification at runtime of the optimiser in our case (Smalltalk + same runtime), though crashes.
Restrictive.

\subsection{Metacircular VMs}

Klein and failure ~\cite{Unga05b}

Jikes RVM aka Jalapeno \cite{Alp99a}

Maxine ~\cite{Wimm13a}

In general this problem is solved, for example with magic or threads (Jalapeno).

Mention Bee Smalltalk and paper and say not open source yet.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}

In this chapter we discussed the main issue existing because the optimiser and the deoptimiser are implemented in Smalltalk and are running in the same runtime and the same native thread than the application they optimise and deoptimise respectively. The main issue is related to infinite recursion. If a hot spot is detected inside the optimiser code, the optimiser may call itself indefinitely to try to optimise it. The deoptimiser has a similar issue when it needs to deoptimise its own code. In both cases, the program may get slow or gets completely stuck.

The optimiser solves this issue by disabling itself when it runs in critical mode (when it interrupts temporarily the application green thread to perform the optimisation). The optimiser cannot optimise itself directly while running in critical mode, it can only optimise the  application, which may include libraries used both by the application and the optimiser itself. For functions taking a long time to optimise, the optimiser cannot stop the application for too long or the application becomes unresponsive, hence it postpone the optimisation to a background compilation queue where functions are optimised when the application is in idle. When performing optimisations in the background, the optimiser can optimise itself entirely.

The deoptimiser cannot solve the problem the same way as it cannot be disabled at any time or Smalltalk code cannot be executed any more. The deoptimiser avoids the problem by being written using a small number of classes that cannot be optimised nor call any other libraries.

\ifx\wholebook\relax\else
    \end{document}
\fi