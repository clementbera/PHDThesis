\ifx\wholebook\relax\else

% --------------------------------------------
% Lulu:

    \documentclass[a4paper,12pt,twoside]{../includes/ThesisStyle}

	\input{../includes/macros}
	\input{../includes/formatAndDefs}

	\graphicspath{{.}{../figures/}}
	\begin{document}
\fi

\chapter{Introduction}
\label{chap:intro}
\minitoc

\section{Context}

We need a small intro about VM in general and disambiguate with OS VMs.

\subsection{Virtual machines for high-level programming languages}

Many high-level object-oriented programming languages run on top of a virtual machine (VM) which provides certain advantages from running directly on the underlying hardware. Many of these programming languages pursue a strict separation between language-side and VM-side. VMs for instance provide automatic memory management or use platform agnostic instructions such as bytecodes. These properties allow a programming language to develop independently from the underlying hardware.

High performance VMs, such as Java HotSpot or current Javascript VMs achieve high performance through just-in-time compilation techniques: once the VM has detected that a portion of code is frequently used, it recompiles it on-the-fly with speculative optimizations based on previous runs of the code. If usage patterns change and the code is not executed as previously speculated anymore, the VM dynamically deoptimizes the execution stack and resumes execution with the unoptimized code.

Originally VMs were built in performance oriented low-level programming languages such as C. However, as the VMs were reaching higher and higher performance, the complexity of their code base increased and some VMs started to get written in higher-level languages as an attempt to ease develpment. Such VMs got written either in the language run by the VM itself or in specific DSLs.

\subsection{Pharo programming language}

In this thesis the focus is on a specific high-level object-oriented programming language, the Smalltalk dialect named Pharo. In Pharo, everything is an object, including classes, bytecoded versions of methods or processes. It is dynamically-typed and every call is a virtual call. The VM relies on a bytecode interpreter and a baseline JIT to gain performance. Modern Smalltalk dialects directly inherit from Smalltalk-80 specified in CITE (Goldberg  Robson 1983) but have evolved during the past 35 years. For example, real closures and exceptions were added.

As Pharo is evolving, the community is looking for better VM performance. Compared to many high performance VMs, the Pharo VM is lacking an optimising JIT with speculative optimisations. However, in high performance VMs, the optimising JIT is one of the most complex part, if not the most complex and the Pharo community has just enough ressources to fund the maintenance and evolution of the existing VM. Hence, the optimising JIT design has to be done under two main constraints:
\begin{itemize}
\item The maintenance of the resulting VM has to remain affordable
\item The resulting VM should be built on top of the existing runtime
\end{itemize}

A first design emerged in the early 2000s according to those constraints. The main ideas were:
\begin{itemize}
	\item To build the optimising JIT in the Pharo runtime itself. The existing VM is written in a DSL compiling to native code through C. As the DSL semantics are very close to C and that most people in the Smalltalk community are either not familiar with C or more productive with Smalltalk than C, this design was seen as a way to reduce the maintenance cost.
	\item To build the optimising JIT as a bytecode to bytecode optimiser and reuse the baseline JIT as a back-end of the optimising JIT to produce efficent machine code. This design would avoid implementing and maintaining two native code back-ends while reusing and extending the existing language-VM interface with the bytecodes, overall lowering the development cost.
\end{itemize}

The design looked interesting but was very abstract so it was unclear how multiple part of the system would be implemented. The thesis started from this proposal and explore multiple aspects of the design that are different from existing designs, especially their advantages and issues.

\section{Problem}

The existing proposal is in multiple ways close to the Graal compiler running on top of the Java hotspot VM (CITE). In this case, the optimising JIT is written in Java and runs in the same runtime than the Java application (though in different threads). 

One of the main difference is that the Graal compiler produces machine code which is handed over to the VM (holding the bytecode interpreter and the baseline JIT) to be installed. In this context, we studied the interface between the in-language optimising JIT and the rest of the VM. One of the goal was to build a small but expressive interface between the two elements.

Then, as the attempt to implement the proposal was started to work, we analysed the interaction between optimising JITs and Smalltalk-style \emph{snapshots}. In Smalltalk, a normal programmer regularly takes a snapshot, a memory dump of all the existing objects, to save the running system state. The Smalltalk VM is able to resume execution from a snapshot, restoring all the object states and resuming all running processes. Each process has its own execution stack, which may refer to optimised code, which is normally not kept across multiple start-ups. With the bytecode to bytecode optimisation design, we focused on the persistance of running processes, including the persistance of optimised code refered by such processes.

Lastly, as the implementation was getting more stable, we focused on tests and validation processes to ensure the correctness of the system. Testing and validating the correctness of an optimising JIT compiler is a difficult task. As the design splits this part of the VM in two independent parts, with the optimising bytecode to bytecode JIT in the language and the back-end as the baseline JIT in the VM, it is possible to consider testing and validating each part of the optimising JIT separatedly.

The thesis focuses on these three problems:

\begin{itemize}
	\item \emph{Problem 1:} How to design a minimal interface between the VM and the language in the context of a language-side optimising JIT ?
	\item \emph{Problem 2:} How to persist the runtime state across multiple VM start-up, including the running processes state and the optimised code state ?
	\item \emph{Problem 3:} Is it possible to validate the language-side optimising JIT independently from the back-end ?
\end{itemize}

\section{Contributions}

we implemented to validate blabla. PArt of it is integrated, other part is available as separate MIT project.

\section{Artifacts}

\section{Outline}



\ifx\wholebook\relax\else
    \end{document}
\fi