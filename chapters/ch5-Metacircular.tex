\ifx\wholebook\relax\else

% --------------------------------------------
% Lulu:

    \documentclass[a4paper,12pt,twoside]{../includes/ThesisStyle}

	\input{../includes/macros}
	\input{../includes/formatAndDefs}

	\graphicspath{{.}{../figures/}}
	\begin{document}
\fi

\chapter{Metacircular optimising and deoptimising processes}
\label{chap:metacircular}
\minitoc

By design, the runtime optimiser and deoptimiser are written in Smalltalk and are running in the same runtime than the optimised application. This design leads to multiple problems existing in metacircular virtual machine. For example, if the deoptimier requires to deoptimise itself, how can we avoid the infinite recursion problem where the deoptimiser calls itself indefinitely ?

As Pharo is currently single-threaded, it is not possible to run Scorch in a concurrent native thread. To optimise code, Scorch requires either to interrupt the application green thread temporarily while optimising code or to postpone the optimisation to a background-priority green thread. The deoptimiser cannot however postpone its tasks as it would block completely the running application, hence it has to interrupt the application green thread until the deoptimisation is done.

This chapter details the advantages and the limitations of having both the optimiser and the deoptimiser in Smalltalk. It includes the different problem met and how they are solved in our implementation. Lastly, we compare our approach with similar VMs and discuss the different solutions. 

%Doc: blog post Sista chronicles 1, an update on the sista, talks at ESUG and Smalltalks + arch paper

\section{In-language optimiser}

Cogit was extended to detect frequently used portion of code based on profiling counters. When such a portion of code is detected, Cogit triggers a call-back to start the optimisation process in the language. In most cases, Scorch decides to stop the current process, find a function to optimise, optimise and install it, then resume the process, resuming the application. At the next call of the function, the optimised version is going to be used. 

To avoid blocking the application thread for too long, the compilation time of Scorch is limited to a fixed amount of time, called \emph{TimeBeforePostponing} (currently 50 ms). The limitation is enforced in Smalltalk by a high-priority green thread, set to stop the compilation process after the amount of time. In practice, most optimisations can be done quickly enough. If the time limit is reached, the optimisation process is postponed to a background green thread to be performed once the application is in idle.

An interesting property of the optimiser is that it can fail. If anything happens so that Scorch cannot generate optimised code within its time limit, Scorch can simply ignore the given code and the execution keeps going with non optimised code. Currently the optimisation is postponed in the background green thread if the optimisation takes too long, but even then, sometimes the background green thread compilation queue may be discarded because new code is load ed or installed. Lastly, as the optimiser grows in maturity the optimisation passes grow in complexity, and it can be that very narrow cases are not correctly handled in the optimiser raising exception. In this case, the optimiser is configured so that any exception escaping the framework leads to the code to be marked as non optimiseable, but the execution can resume just fine with non optimised code.

\subsection{Dependencies.} 

The first constraint to note when programming Scorch, which may be obvious to the Kernel programmer, is that Scorch cannot depends on any framework or library but the Kernel and Core librairies. Each framework or library in the system relies on the execution engine to perform its code. Scorch is part of the execution engine. Hence, if Scorch relies on an external librairy and that someone modifies the library, the execution engine may not be stable any more and the runtime completely crashes. In fact, all the Kernel code and Core librairies have similar constraints, they cannot rely on anything to keep the system modular. 

While writting Scorch, we needed a tool to compress the deoptimisation metadata generated aside from the optimised code. We wanted to use the standard Pharo serializer, Fuel (CITE), but we were not able to do it or further modification on Fuel would break the execution engine.

In the end, we limited the dependencies of Scorch to the Pharo Kernel and the core collections (exactly: Set, OrderedCollection, Array, ByteArray and Dictionary in addition to the kernel). Any change on one of this dependency may require to change something in Scorch to keep the system running.

\subsection{Infinite recursion}

As Scorch is written in Smalltalk, it can theoretically be triggered on its own code. In practice, if Scorch is triggered on itself, it may lead to an infinite recursion. Indeed, each time Scorch tries to optimise anything, before reaching the point where it can install an optimised function, it may interrupt itself to start optimising one of its own function. If a frequent portion of code is detected at each run of Scorch, the program gets stuck in an infinite recursion where Scorch keeps starting to optimise one of its function without reaching the point where the function is installed.

In the current environment used for benchmarking, a global flag exists to know it exists one green thread currently performing runtime optimisation by blocking an application thread. The flag is set when the call-back to activate Scorch is executed. When set, the call-back is disabled so that no infinite recursion can happen. As the Scorch compilation process is limited to a fixed amount of time, the flag cannot be continuously set for more than this amount of time.

The flag approach has a significant advantage: it is quite simple both conceptually and implementation-wise, while it completely avoids the infinite recursion problem. It has however a major drawback: Scorch cannot optimise its own code any more. Of course, Scorch uses core libraries that can be optimised. The main case are the core collections, if the application optimised is also using core collections, they may get optimised, then Scorch ends up using an optimised collection library. For this reason, it is possible that while optimising code Scorch triggers the deoptimiser, and it works perfectly fine.

\paragraph{Future work and discussion.} Alternatively to the flag approach, the optimiser could decide to add any function requiring runtime optimisation to the existing background green thread, so that Scorch could be optimised when the application is in idle. We investigated in that direction, but when the VM triggers the call-back to start optimising code, Scorch needs to figure out based on the current stack what function to optimise. In many case, the frequently used function is inside a loop, and most loops in Smalltalk are run using high level constructs using closures, hence Scorch needs to optimise the function of another frame than the bottom frame. The code searching the stack for the function to optimise is also written in Smalltalk as part of Scorch, hence adding a function to the background green thread while avoiding infinite recursion is not that obvious. Further investigation in this direction is required in the future.

Another alternative to the flag approach would be to optimise the runtime compiler statically, using it on itself either without performing optimisations requiring type speculation or with runtime type information statically computed from warm-up runs. 

\subsection{Debugging and runtime modification}

%Maybe rewrite so that formally does not work but in practice it does.

As any Smalltalk program, it is possible to modify the optimiser while it is running, for example in the debugger. If the modifications leads to incorrect optimiser behavior, then the runtime may crash. To avoid crashes, it may be wise to disable the optimiser while editing it. In practice, this feature is used only by the optimiser implementors. It is very useful to debug the optimiser to understand specific bugs or compiler decisions. With careful understanding of the infrastructure, it is possible in practice to debug the optimiser while it is running and modify its code. The optimiser is set by default to catch all exceptions, failing the optimisation of a specific v-function if an exception was raised. Hence, if the code modification triggers a compile-time exception, the system shall not crash. Unfortunately, in some cases, the optimiser may have silent errors, generating incorrect code without raising exceptions and completely crashing the system.

The only part of Scorch that cannot really be edited is the deoptimisation metadata generation. Indeed, deoptimisation metadata is also used by the deoptimiser which, as detailled in the following section, has stronger constraints on its code. If one modifies the deoptimisation metadata generated, the deoptimiser may not be able to deoptimise correctly optimised code any more, leading to crashes.

\section{In-language deoptimiser}

The trap instruction is present in the extended bytecode set and when reached through execution flow, Cogit triggers a call-back to the deoptimiser. In addition, multiple tools in the language, such as the debugging tools, have been changed to call the deoptimiser when the programmer attempts to introspect the stack.

On the contrary to the optimiser, deoptimisation cannot be postponed to a background green thread, or the application green thread may be blocked until the application reaches idle state. In addition, deoptimisation cannot fail or the runtime crashes. If the optimiser failed to create an optimised function, then the execution could simply fall back to non optimised code. If the deoptimiser fails to recreate a non optimised version of the stack, then the system crashes or the application green thread has to be terminated.

As the deoptimiser cannot fail, it is not possible to solve the infinite recursion problem in the same way than the optimiser. If the deoptimiser request deoptimisation, as for the optimiser requesting optimisation, the programs ends up in an infinite recursion where it keeps deoptimising / optimising itself. In the case of the optimiser, we could simply disable it while it is running, and the entire problem was solved. In the case of the deoptimiser, if we disable it and the deoptimiser request deoptimisation, the program cannot resume using non optimised code and crashes. 

To solve this infinite recursion problem, we implemented two solutions. The first solution attempts to restore the system in a recovery mode when recursive deoptimisation happens. It was used for the first benchmark, but it did not work correctly with benchmarks creating multiple green threads, and making it thread-safe had too many constraints. Then a second solution, used now, was designed and consists in keeping all the deoptimiser code in a library completely independent from the rest of the system that cannot be optimised.

\subsection{Recovery mode}

In this first solution to the infinite recursion problem for deoptimisation, we attempted to keep a recovery state of the whole system. More precisely, Scorch kept a copy of the method dictionaries

 Attempt to recovery state with limited portion that cannot be optimised, issues with green threads and complexity, made it independent.

cannot optimie until flag set / reset.

- recovery state (not working with threads)

too difficult to make thread safe because then up until the flag is set we could not optimise hence can't optimise code in process scheduler.

\subsection{Independent library}

- completely independent and forbid deopt / opt

We could opt it statically.

Strong constraints: no dependency at all (duplicate array and dict), debugging is hardly possible.

Example of debugging -> can't log from deoptimiser. 

\subsection{Debugging and runtime modification}

Modifying the deoptimiser while it is running is also more complex than the optimiser. Optimised code is present in the runtime, and any modification of the deoptimiser is

- any change imply existing code cannot be deopt and hard crashes.

\section{Related work}

\subsection{DSL compiled to machine code}

Modification at runtime of the optimiser in our case (Smalltalk + same runtime), though crashes.
Restrictive.

\subsection{Metacircular VMs}

In general this problem is solved, for example with magic or threads (Jalapeno).

\subsection{Graal}

Stack search and deoptimisation in the VM

\ifx\wholebook\relax\else
    \end{document}
\fi